1–1 A HISTORICAL BACKGROUND
• Events leading to development of  the microprocessor.
• 80X86, Pentium, Pentium Pro, Pentium III, Pentium 4, and Core2 microprocessors.
• While not essential to understand the microprocessor, furnishes:
  – interesting reading
  – historical perspective of fast-paced evolution

The Mechanical Age
• Idea of computing system not new.
• Calculating with a machine dates to 500 BC.
• Ancient people invented the abacus.
  – first mechanical calculator
  – strings of beads perform calculations
• Used by ancient priests to keep track of storehouses of grain.
  – still in use today
• In 1642 mathematician Blaise Pascal invented a calculator constructed of gears and wheels.
  – each gear contained 10 teeth
• When moved one complete revolution, a second gear advances one place.
  – same principle used in automobile odometer
• Basis of all mechanical calculators.
• PASCAL programming language is named in honor of Blaise Pascal.
• First practical geared mechanical machines to compute information date to early 1800s.
  – humans dreamed of mechanical machines that could compute with a program
• One early pioneer of mechanical computing machinery was Charles Babbage.
  – aided by Ada Byron, Countess of Lovelace
• Commissioned in 1823 by Royal Astronomical Society to build programmable calculating  machine.
  – to generate Royal Navy navigational tables
• He began to create his Analytical Engine.
• Steam-powered mechanical computer.
  – stored a thousand 20-digit decimal numbers
• Variable program could modify function of the machine to perform various calculating tasks.
  – input through punched cards, much as computers in the 1950s and 1960s used punched cards
• It is assumed idea of punched cards is from Joseph Jacquard, a Frenchman.
  – used punched cards as input to a weaving machine he invented in 1801
  • Jacquard’s loom used punched cards to select intricate weaving patterns in cloth it produced.
  – punched cards programmed the loom
• After many years of work Babbage’s dream began to fade.
  – machinists of his day unable to create the parts needed to complete his work
• Analytical Engine required more than 50,000
  machined parts.
  – they could not be made with enough precision to
    allow his engine to function reliably

The Electrical Age
• 1800s saw advent of the electric motor.
  – conceived by Michael Faraday
• Also a multitude of electrically motor-driven adding machines based on the Pascal
  mechanical calculator.
  – common office equipment until 1970s
• Introduced by Bomar Corporation the Bomar Brain, was a handheld electronic calculator.
  – first appeared in early 1970s
• Monroe also pioneer of electronic calculators, making desktop models.
  – four-function; size of cash registers
• In 1889, Herman Hollerith developed the punched card for storing data.
  – apparently also borrowed Jacquard ideas
• Also developed mechanical machine that counted, sorted, and collated information stored on punched cards.
  – driven by one of the new electric motors
• Calculating by machine intrigued US govt.
  – Hollerith commissioned to use system to store and tabulate 1890 census information
• In 1896 Hollerith formed Tabulating Machine Company.
  – developed line of machines using punched cards for tabulation
• After a number of mergers, Tabulating Machine Co. was formed into International Business Machines Corporation.
  – referred to more commonly as IBM, Inc.
• Punched cards used in early computer systems often called Hollerith cards.
  – in honor of Herman Hollerith
• 12-bit code used on a punched card is called the Hollerith code.
• Mechanical-electric machines dominated information processing world until 1941.
  – construction of first electronic calculating machine
• German inventor Konrad Zuse, invented the first modern electromechanical computer.
• His Z3 calculating computer probably invented for aircraft and missile design.
  – during World War II for the German war effort
• Z3 a relay logic machine clocked at 5.33 Hz.
  – far slower than latest multiple GHz
• Had Zuse been given adequate funding, likely would have developed a much more powerful computer system.
• In 1936 Zuse constructed a mechanical version of his system.
• In 1939 constructed first electromechanical computer system, called the Z2.
  – Zuse today receiving belated honors for pioneering work in the area of digital electronics
• First electronic computer placed in operation to break secret German military codes.
• recently discovered through declassification of military documents of 1943.
• System invented by Alan Turing.
  – used vacuum tubes,
• Turing called his machine Colossus (huge statue).
  – probably because of its size
• Although design allowed it to break secret
  German military codes generated by the mechanical Enigma machine, it could not solve other problems.
• Colossus not programmable
• A fixed-program computer system
  – today often called a special-purpose computer
• First general-purpose, programmable electronic computer system developed 1946.
  – at University of Pennsylvania
• Electronic Numerical Integrator and Calculator (ENIAC), a huge machine.
  – over 17,000 vacuum tubes; 500 miles of wires
  – weighed over 30 tons
  – about 100,000 operations per second
• Programmed by rewiring its circuits.
  – process took many workers several days
  – workers changed electrical connections on plug- boards like early telephone switchboards
• Required frequent maintenance.
  – vacuum tube service life a problem
• December 23, 1947, John Bardeen, William Shockley, and Walter Brattain develop the transistor at Bell Labs.
• Followed by 1958 invention of the integrated circuit (IC) by Jack Kilby of Texas Instruments.
• IC led to development of digital integrated circuits in the 1960s.
  – RTL, or resistor-to-transistor logic
• First microprocessor developed at Intel Corporation in 1971.
• Intel engineers Federico Faggin, Ted Hoff, and Stan Mazor developed the 4004 microprocessor.
• U.S. Patent 3,821,715.
• Device started the microprocessor revolution continued today at an ever-accelerating pace. Programming Advancements
• Once programmable machines developed, programs and programming languages began to appear.
• As early practice of rewiring circuits proved too cumbersome, computer languages began to appear in order to control the computer.
• The first, machine language, was constructed of ones and zeros using binary codes.
  – stored in the computer memory system as groups of instructions called a program
• More efficient than rewiring a machine to program it.
  – still time-consuming to develop a program due to sheer number of program codes required
• Mathematician John von Neumann first modern person to develop a system to accept instructions and store them in memory.
• Computers are often called von Neumann machines in his honor.
  – recall that Babbage also had developed the concept long before von Neumann
• Once systems such as UNIVAC became available in early 1950s, assembly language was used to simplify entering binary code.
• Assembler allows programmer to use mnemonic codes…
  – such as ADD for addition
• In place of a binary number.
  – such as 0100 0111
• Assembly language an aid to programming.
• 1957 Grace Hopper developed first high-level programming language called FLOWMATIC.
  – computers became easier to program
• In same year, IBM developed FORTRAN FORmula TRANslator) for its systems.
  – Allowed programmers to develop programs that used formulas to solve mathematical problems.
• FORTRAN is still used by some scientists for computer programming.
  – Similar language, ALGOL (ALGOrithmic Language) introduced about a year later
• First successful, widespread programming language for business applications was
  COBOL (COmputer Business Oriented Language).
• COBOL usage diminished in recent years.
  – still a player in some large business and government systems
• Another once-popular business language is RPG (Report Program Generator).
  – allows programming by specifying form of the input, output, and calculations
• Since early days of programming, additional languages have appeared.• Some common modern programming languages are BASIC, C#, C/C++, Java, PASCAL, and ADA.
  – BASIC and PASCAL languages both designed as teaching languages, but escaped the classroom.
• BASIC used in many computer systems.
  – among most common languages today
  – probably easiest of all to learn
• Estimates indicate BASIC used for 80% of programs written by personal computer users.
• Visual BASIC, has made programming in the Windows environment easier.
  – could supplant C/C++ and PASCAL as a scientific language, but is doubtful
• C# language is gaining headway.
  – may actually replace C/C++ and most other languages including Java
  – may eventually replace BASIC
• Which becomes dominant remains in future.
• Scientific community uses primarily C/C++.
  – occasionally PASCAL and FORTRAN
• Recent survey of embedded system developers showed C was used by 60%.
  – 30% used assembly language
  – remainder used BASIC and JAVA
• These languages allow programmer almost complete control over the programming environment and computer system.
  – especially C/C++
• C/C++ replacing some low-level machine control software or drivers normally reserved for assembly language.
• Assembly language still plays important role.
  – many video games written almost exclusively in assembly language
• Assembly also interspersed with C/C++ to perform machine control functions efficiently.
  – some newer parallel instructions found on Pentium and Core2 microprocessors only programmable in assembly language
• ADA used heavily by Department of Defense.
• The ADA language was named in honor of Augusta Ada Byron, Countess of Lovelace.
• The Countess worked with Charles Babbage in the early 1800s.
  – development of software for Analytical Engine

The Microprocessor Age
• World’s first microprocessor the Intel 4004.
• A 4-bit microprocessor-programmable controller on a chip.
• Addressed 4096, 4-bit-wide memory locations.
  – a bit is a binary digit with a value of one or zero
  – 4-bit-wide memory location often called a nibble
• The 4004 instruction set contained 45 instructions.
• Fabricated with then-current state-of-the-art P-channel MOSFET technology.
• Executed instructions at 50 KIPs (kilo-instructions per second).
  – slow compared to 100,000 instructions per second by 30-ton ENIAC computer in 1946
• Difference was that 4004 weighed less than an ounce.
• 4-bit microprocessor debuted in early game systems and small control systems.
  – early shuffleboard game produced by Bailey
• Main problems with early microprocessor were speed, word width, and memory size.
• Evolution of 4-bit microprocessor ended when Intel released the 4040, an updated 4004.
  – operated at a higher speed; lacked improvements in word width and memory size
• Texas Instruments and others also produced 4-bit microprocessors.
  – still survives in low-end applications such as microwave ovens and small control systems
  – Calculators still based on 4-bit BCD (binary- coded decimal) codes
• With the microprocessor a commercially viable product, Intel released 8008 in 1971.
  – extended 8-bit version of 4004 microprocessor
• Addressed expanded memory of 16K bytes.
  – A byte is generally an 8-bit-wide binary number and a K is 1024.
  – memory size often specified in K bytes
• Contained additional instructions, 48 total.
• Provided opportunity for application in more advanced systems.
  – engineers developed demanding uses for 8008
• Somewhat small memory size, slow speed, and instruction set limited 8008 usefulness.
• Intel introduced 8080 microprocessor in 1973.
  – first of the modem 8-bit microprocessors
• Motorola Corporation introduced MC6800 microprocessor about six months later.
• 8080—and, to a lesser degree, the MC6800—ushered in the age of the microprocessor.
  – other companies soon introduced their own versions of the 8-bit microprocessor
• Only Intel and Motorola continue to create new, improved microprocessors.
  – IBM also produces Motorola-style microprocessors
• Motorola sold its microprocessor division.
  – now called Freescale Semiconductors, Inc.
• Zilog still manufactures microprocessors.
  – microcontrollers and embedded controllers instead of general-purpose microprocessors

What Was Special about the 8080?
• 8080 addressed four times more memory.
  – 64K bytes vs l6K bytes for 8008
• Executed additional instructions; 10x faster.
  – addition taking 20 µs on an 8008-based system required only 2.0 µs on an 8080-based system
• TTL (transistor-transistor logic) compatible.
  – the 8008 was not directly compatible
• Interfacing made easier and less expensive.
• The MITS Altair 8800, was released in 1974.
  – number 8800 probably chosen to avoid copyright violations with Intel
• BASIC language interpreter for the Altair 8800 computer developed in 1975.
  – Bill Gates and Paul Allen, founders of Microsoft Corporation
• The assembler program for the Altair 8800 was written by Digital Research Corporation.
  – once produced DR-DOS for the personal computer

The 8085 Microprocessor
• In 1977 Intel Corporation introduced an updated version of the 8080—the 8085.
• Last 8-bit, general-purpose microprocessor developed by Intel.
• Slightly more advanced than 8080; executed software at an even higher speed.
  – 769,230 instructions per second vs 500,000 per second on the 8080).
   
• Main advantages of 8085 were its internal clock generator and system controller, and higher clock frequency.
  – higher level of component integration reduced the 8085’s cost and increased its usefulness
• Intel has sold over 100 million of the 8085.
  – its most successful 8-bit, general-purpose microprocessor.
  – also manufactured by many other companies, meaning over 200 million in existence
• Applications that contain the 8085 will likely continue to be popular.
• Zilog Corporation sold 500 million of their 8-bit Z80microprocessors.
• The Z-80 is machine language–compatible with the 8085.
• Over 700 million microprocessors execute 8085/Z-80 compatible code.

The Modern Microprocessor
• In 1978 Intel released the 8086; a year or so later, it released the 8088.
• Both devices are 16-bit microprocessors.
  – executed instructions in as little as 400 ns (2.5 millions of instructions per second)
  – major improvement over execution speed of 8085
• 8086 & 8088 addressed 1M byte of memory.
  – 16 times more memory than the 8085
  – 1M-byte memory contains 1024K byte-sized memory locations or 1,048,576 bytes
• Higher speed and larger memory size allowed 8086 & 8088 to replace smaller minicomputers in many applications.
• Another feature was a 4- or 6-byte instruction cache or queue that prefetched instructions before they were executed.
  – queue sped operation of many sequences of instruction
  – basis for the much larger instruction caches found in modem microprocessors.
• Increased memory size and additional instructions in 8086/8088 led to many sophisticated applications.
• Improvements to the instruction set included multiply and divide instructions.
  – missing on earlier microprocessors
• Number of instructions increased.
  – from 45 on the 4004, to 246 on the 8085
  – over 20,000 variations on the 8086 & 8088
• These microprocessors are called CISC (complex instruction set computers).
  – additional instructions eased task of developing efficient and sophisticated applications
• 16-bit microprocessor also provided more internal register storage space.
  – additional registers allowed software to be written more efficiently
  – evolved to meet need for larger memory systems
• Popularity of Intel ensured in 1981 when IBM chose the 8088 in its personal computer.
• Spreadsheets, word processors, spelling checkers, and computer-based thesauruses were memory-intensive .
  – required more than 64K bytes of memory found in 8-bit microprocessors to execute efficiently
  – The 16-bit 8086 and 8088 provided 1M byte of memory for these applications

The 80286 Microprocessor
• Even the 1M-byte memory system proved limiting for databases and other applications.
  – Intel introduced the 80286 in 1983
  – an updated 8086
• Almost identical to the 8086/8088.
  – addressed 16M-byte memory system instead of a 1M-byte system
• Instruction set almost identical except for a few additional instructions.
  – managed the extra 15M bytes of memory
  • 80286 clock speed increased in 8.0 Mhz version.
  – executed some instructions in as little as 250 ns  (4.0 MIPs)
• Some changes to internal execution of instructions led to eightfold increase in speed for many instructions.

The 32-Bit Microprocessor
• Applications demanded faster microprocessor speeds, more memory, and wider data paths.
• Led to the 80386 in 1986 by Intel.
  – major overhaul of 16-bit 8086–80286 architecture
• Intel’s first practical microprocessor to contain a 32-bit data bus and 32-bit memory address.
  – Intel produced an earlier, unsuccessful 32-bit microprocessor called iapx-432
• Through 32-bit buses, 80386 addressed up to 4G bytes of memory.
  – 1G memory = 1024M, or 1,073,741,824 locations
  – 1,000,000 typewritten, double-spaced pages of ASCII text data
• 80386SX addressed 16M bytes of memory through a 16-bit data and 24-bit address bus.
• 80386SL/80386SLC addressed 32M bytes memory via 16-bit data, 25-bit address bus.
• 80386SLC contained an internal cache to process data at even higher rates.
• Intel released 80386EX in 1995.
• Called an embedded PC.
    – contains all components of the AT class computer on a single integrated circuit
•   24 lines for input/output data.
•   26-bit address bus; 16-bit data bus.
•   DRAM refresh controller.
•   Programmable chip selection logic
• Applications needing higher speeds and large memory systems include software systems that use a GUI, or graphical user interface
• Modern graphical displays contain 256,000 or more picture elements (pixels, or pels).
• VGA (variable graphics array) resolution is 640 pixels per scanning line by 480 lines.
  – resolution used to display computer boot screen
• To display one screen of information, each picture element must be changed.
  – requires a high-speed microprocessor
• GUI packages require high microprocessor speeds and accelerated video adapters for quick and efficient manipulation of video text and graphical data.
  – the most striking system is Microsoft Windows
• GUI often called a WYSIWYG (what you see is what you get) display.
• 32-bit microprocessor needed due to size of its data bus.
  – transfers real (single-precision floating-point) numbers that require 32-bit-wide memory
• To process 32-bit real numbers, the microprocessor must efficiently pass them between itself and memory.
  – with 8-bit data bus, takes four read or write cycles
  – only one read or write cycle is required for 32 bit
• Significantly increases speed of any program that manipulates real numbers.
• High-level languages, spreadsheets, and database management systems use real numbers for data storage.
  – also used in graphical design packages that use vectors to plot images on the video screen
  – CAD (computer-aided drafting/design) systems as AUTOCAD, ORCAD
• 80386 had higher clocking speeds and included a memory management unit.
  – allowed memory resources to be allocated and managed by the operating system
• 80386 included hardware circuitry for memory management and assignment.
  – improved efficiency, reduced software overhead
  – earlier microprocessors left memory management completely to the software
• Instruction set, memory management upward-compatible with 8086, 8088, and 80286.
  – additional instructions referenced 32-bit registers and managed the memory system
• Features allowed older, 16-bit software to operate on the 80386 microprocessor.

The 80486 Microprocessor
•   In 1989 Intel released the 80486.
•   Highly integrated package.
•   1. 80386-like microprocessor.
•   2. 80387-like numeric coprocessor.
•   3. 8K-byte cache memory system.
• Internal structure of 80486 modified so about half of its instructions executed in one clock instead of two clocks.
  – in a 50 MHz version, about half of instructions executed in 25 ns (50 MIPs)
  – 50% over 80386 operated at same clock speed
• Double-clocked 80486DX2 executed instructions at 66 MHz, with memory transfers at 33 MHz.
  – called a double-clocked microprocessor
• A triple-clocked version improved speed to 100 MHz with memory transfers at 33 MHz.
  – about the same speed as 60 MHz Pentium.
• Expanded 16K-byte cache.
  – in place of standard 8K-byte cache
• Advanced Micro Devices (AMD) produced a triple-clocked version with a bus speed of 40 MHz and a clock speed of 120 MHz.
• The future promises rates 10 GHz or higher.
• Other versions called OverDrive processors.
  – a double-clocked 80486DX that replaced an 80486SX or slower-speed 80486DX
  – functioned as a doubled-clocked version of the microprocessor
